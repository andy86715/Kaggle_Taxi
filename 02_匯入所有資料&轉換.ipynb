{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import dask.dataframe as dd\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "TRAIN_PATH = '/Volumes/transcend/大檔案/Taxi/NYT/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact number of rows: 55423857\n",
      "CPU times: user 23 s, sys: 23.3 s, total: 46.3 s\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Assume we only know that the csv file is somehow large, but not the exact size\n",
    "# we want to know the exact number of rows\n",
    "\n",
    "with open(TRAIN_PATH) as file:\n",
    "    n_rows = len(file.readlines())\n",
    "\n",
    "print('Exact number of rows: {n_rows}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traintypes = {'fare_amount': 'float32',\n",
    "              'pickup_datetime': 'str', \n",
    "              'pickup_longitude': 'float32',\n",
    "              'pickup_latitude': 'float32',\n",
    "              'dropoff_longitude': 'float32',\n",
    "              'dropoff_latitude': 'float32',\n",
    "              'passenger_count': 'uint8'}\n",
    "\n",
    "cols = list(traintypes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chunksize = 5000000 # 5 million rows at one go. Or try 10 million"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 2min 8s, sys: 14.6 s, total: 2min 23s\n",
      "Wall time: 2min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_list = [] # list to hold the batch dataframe\n",
    "\n",
    "for df_chunk in tqdm_notebook(pd.read_csv(TRAIN_PATH, usecols=cols, dtype=traintypes, chunksize=chunksize)):\n",
    "     \n",
    "    # Neat trick from https://www.kaggle.com/btyuhas/bayesian-optimization-with-xgboost\n",
    "    # Using parse_dates would be much slower!\n",
    "    df_chunk['pickup_datetime'] = df_chunk['pickup_datetime'].str.slice(0, 16)\n",
    "    df_chunk['pickup_datetime'] = pd.to_datetime(df_chunk['pickup_datetime'], utc=True, format='%Y-%m-%d %H:%M')\n",
    "    \n",
    "    # Can process each chunk of dataframe here\n",
    "    # clean_data(), feature_engineer(),fit()\n",
    "    \n",
    "    # Alternatively, append the chunk to list and merge all\n",
    "    df_list.append(df_chunk) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55423856 entries, 0 to 55423855\n",
      "Data columns (total 7 columns):\n",
      "fare_amount          float32\n",
      "pickup_datetime      datetime64[ns, UTC]\n",
      "pickup_longitude     float32\n",
      "pickup_latitude      float32\n",
      "dropoff_longitude    float32\n",
      "dropoff_latitude     float32\n",
      "passenger_count      uint8\n",
      "dtypes: datetime64[ns, UTC](1), float32(5), uint8(1)\n",
      "memory usage: 1.5 GB\n"
     ]
    }
   ],
   "source": [
    "# Merge all dataframes into one dataframe\n",
    "df = pd.concat(df_list)\n",
    "\n",
    "# Delete the dataframe list to release memory\n",
    "del df_list\n",
    "\n",
    "# See what we have loaded\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 匯出成Feather格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.31 s, sys: 4.37 s, total: 8.68 s\n",
      "Wall time: 35.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Save into feather format, about 1.5Gb.\n",
    "df.to_feather('/Volumes/transcend/大檔案/Taxi/NYT/nyc_taxi_data_raw.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
